shiny::runApp('seminarioHD/elogiosApp2')
runApp('seminarioHD/elogiosApp2')
runApp('seminarioHD/elogiosApp2')
runApp('seminarioHD/elogiosApp2')
gc()
gc()
gc()
gc()
gc()
gc()
gc()
gc()
gc()
gc()
gc()
gc()
gc()
library(reticulate)
?reticulate
shiny::runApp('seminarioHD/elogiosApp2')
runApp('seminarioHD/elogiosApp2')
shiny::runApp('seminarioHD/elogiosR/elogiosAppR')
install.packages("rsconnect")
install.packages("rsconnect")
install.packages("rsconnect")
rsconnect::setAccountInfo(name='manuel-cebral',
token='6F71D75703DF5E90AF9AE7AD88E587D6',
secret='<SECRET>')
rsconnect::setAccountInfo(name='manuel-cebral',
token='6F71D75703DF5E90AF9AE7AD88E587D6',
secret='R2use0DWbExo0ijFgNt6cPpGfLBpGJ9ok6eGrHoe')
shiny::runApp('seminarioHD/elogiosR/elogiosAppR')
library(openai)
Sys.setenv(
OPENAI_API_KEY = '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'
)
create_completion(
model = "ada",
prompt = "Create a praise for a literary author"
)
create_image("An astronaut riding a horse in a photorealistic style")
generate_praise <- function(name) {
prompt <- paste("Generate a praise for", name)
response <- openai_completions(prompt, temperature = 0.7, max_tokens = 50)
praise <- response$choices[[1]]$text
return(praise)
}
name1 <- "Leonard Cohen"
praise1 <- generate_praise(name1)
response <- openai::openai_completions(prompt, temperature = 0.7, max_tokens = 50)
generate_praise <- function(name) {
prompt <- paste("Generate a praise for", name)
response <- openai::openai_completions(prompt, temperature = 0.7, max_tokens = 50)
praise <- response$choices[[1]]$text
return(praise)
}
name1 <- "Leonard Cohen"
praise1 <- generate_praise(name1)
response <- create_chat_completion(prompt, temperature = 0.7, max_tokens = 50)
generate_praise <- function(name) {
prompt <- paste("Generate a praise for", name)
response <- create_chat_completion(prompt, temperature = 0.7, max_tokens = 50)
praise <- response$choices[[1]]$text
return(praise)
}
name1 <- "Leonard Cohen"
praise1 <- generate_praise(name1)
generate_praise <- function(name) {
prompt <- paste("Generate a praise for", name)
response <- create_chat_completion(prompt, temperature = 0.7, max_tokens = 50)
praise <- response$choices[[1]]$text
return(praise)
}
name1 <- "Leonard Cohen"
praise1 <- generate_praise(name1)
generate_praise <- function(name) {
prompt <- paste("Generate a praise for", name)
response <- create_chat_completion(model = "gpt-3.5-turbo", prompt, temperature = 0.7, max_tokens = 50)
praise <- response$choices[[1]]$text
return(praise)
}
praise1 <- generate_praise(name1)
generate_praise <- function(name) {
prompt <- paste("Generate a praise for", name)
response <- create_completion(model = "gpt-3.5-turbo", prompt, temperature = 0.7, max_tokens = 50)
praise <- response$choices[[1]]$text
return(praise)
}
name1 <- "Leonard Cohen"
praise1 <- generate_praise(name1)
reticulate::repl_python()
library(reticulate)
exit
library(reticulate)
py_run_string("import os")
py_run_string("import openai")
py_run_string("from gtts import gTTS")
py_install("gTTS")
py_run_string("from gtts import gTTS")
py_run_string("openai.api_key = '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'")
py_run_string("
response = openai.Completion.create(
engine="text-davinci-003",
py_run_string("
response = openai.Completion.create(
engine='text-davinci-003',
prompt='What dinosaurs lived in the cretaceous period?',
max_tokens=60)")
py_run_string("mytext = response.choices[0].text.strip()")
py_run_string("print(mytext)")
py$response$choices[0]
py$response$choices[0]$text
py$response$choices[0] %>% View()
py$response$choices%>% View()
.[[1]][["text"]]
py$response$choices[[1]][["text"]]
py$response$choices[[1]][["text"]]
py_run_string("
def response (myPrompt, tokens, temp):
openai.Completion.create(
engine='text-davinci-003',
prompt=myPrompt,
max_tokens=tokens,
temperature=temp
)")
py_run_string("
def response (myPrompt, tokens, temp):
openai.Completion.create(
engine='text-davinci-003',
prompt=myPrompt,
max_tokens=tokens,
temperature=temp
)")
source_python("seminarioHD/openAI/data/elogiosAI.py")
py$response("Generate a literary praise for Jorge Luis Borges", 70, 0.6)
maxTokens <- as.integer(70)
py$response("Generate a literary praise for Jorge Luis Borges", maxTokens, 0.6)
respuesta <- py$response("Generate a literary praise for Jorge Luis Borges", maxTokens, 0.6)
respuesta
py_run_string(paste0("
response = openai.Completion.create(
engine='text-davinci-003',
prompt=", myPromt, ",max_tokens=,"",70,')'"))
prompt=", myPromt, ",max_tokens=,""70",")""))
response = openai.Completion.create(engine='text-davinci-003', prompt=", myPromt, ", max_tokens=","70",")""))
)
)
)
)
py_run_string(paste0("
response = openai.Completion.create(engine='text-davinci-003', prompt=",
myPromt,
", max_tokens=",
maxTokens,
")"
))
myPrompt <- "Generate a literary praise for Jorge Luis Borges"
py_run_string(paste0("
response = openai.Completion.create(engine='text-davinci-003', prompt=",
myPromt,
", max_tokens=",
maxTokens,
")"
))
py_run_string(paste0("
response = openai.Completion.create(engine='text-davinci-003', prompt=",
myPrompt,
", max_tokens=",
maxTokens,
")"
))
py_run_string(paste0("
response = openai.Completion.create(engine='text-davinci-003', prompt=",
myPrompt,
", max_tokens=",
maxTokens,
")"
))
py_run_string(paste0("
response = openai.Completion.create(engine='text-davinci-003',
prompt=", myPrompt, ", max_tokens=",
maxTokens,
")"
))
py_run_string(paste0("
response = openai.Completion.create(engine='text-davinci-003', prompt=", myPrompt, ", max_tokens=",
maxTokens,
")"
))
py_run_string(paste0("
response = openai.Completion.create(engine='text-davinci-003', prompt=", myPrompt, ", max_tokens=",
maxTokens,
")"
))
py_run_string("
response = openai.Completion.create(
engine='text-davinci-003',
prompt='What dinosaurs lived in the cretaceous period?',
max_tokens=60)")
py$response$choices[[1]][["text"]]
py_run_string("
response = openai.Completion.create(
engine='text-davinci-003',
prompt='Generate a literary praise for Jorge Luis Borges',
max_tokens=60)")
py$response$choices[[1]][["text"]]
py_run_string("
response = openai.Completion.create(
engine='text-davinci-003',
prompt='Crea un elogio literario para Jorge Luis Borges',
max_tokens=60)")
py$response$choices[[1]][["text"]]
source_python("seminarioHD/openAI/data/elogiosAI.py")
py$response$choices[[1]][["text"]]
py$response
response <- openai::create_completion(engine_id = "gpt-3.5-turbo", prompt, temperature = 0.7, max_tokens = 50)
generate_praise <- function(name) {
prompt <- paste("Generate a praise for", name)
response <- openai::create_completion(engine_id = "text-davinci-003", prompt, temperature = 0.7, max_tokens = 50)
praise <- response$choices[[1]]$text
return(praise)
}
name1 <- "Leonard Cohen"
praise1 <- generate_praise(name1)
praise <- response$choices[1]$text
generate_praise <- function(name) {
prompt <- paste("Generate a praise for", name)
response <- openai::create_completion(engine_id = "text-davinci-003", prompt, temperature = 0.7, max_tokens = 50)
praise <- response$choices[1]$text
return(praise)
}
praise1 <- generate_praise(name1)
cat(paste("Praise for", name1, ":", praise1, "\n"))
generate_praise <- function(name) {
prompt <- paste("Generate a literary praise for", name)
response <- openai::create_completion(engine_id = "text-davinci-003", prompt, temperature = 0.7, max_tokens = 50)
praise <- response$choices[1]$text
return(praise)
}
name1 <- "Leonard Cohen"
praise1 <- generate_praise(name1)
cat(paste("Praise for", name1, ":", praise1, "\n"))
generate_praise <- function(name) {
prompt <- paste("Generate a literary praise for", name)
response <- openai::create_completion(engine_id = "text-davinci-003", prompt, temperature = 0.7, max_tokens = 50)
#praise <- response$choices[1]$text
return(praise)
}
name1 <- "Leonard Cohen"
praise1 <- generate_praise(name1)
generate_praise <- function(name) {
prompt <- paste("Generate a literary praise for", name)
response <- openai::create_completion(engine_id = "text-davinci-003", prompt, temperature = 0.7, max_tokens = 50)
#praise <- response$choices[1]$text
return(response)
}
name1 <- "Leonard Cohen"
praise1 <- generate_praise(name1)
praise1
source_python("seminarioHD/openAI/data/elogiosAI.py")
respuesta <- py$response("Generate a literary praise for Jorge Luis Borges", maxTokens, 0.6)
source_python("seminarioHD/openAI/data/elogiosAI.py")
respuesta <- py$response("Generate a literary praise for Jorge Luis Borges", maxTokens, 0.6)
generate_response <- function(prompt, tokens, temp) {
# Import the Python module containing the generate_response function
openai_module <- import("seminarioHD/openAI/data/elogiosAI.py")  # Replace with the actual module name
# Call the Python function
response <- openai_module$generate_response(prompt, tokens, temp)
return(response)
}
# Example usage:
prompt <- "What dinosaurs lived in the cretaceous period?"
tokens <- 60
temp <- 0.7
result <- generate_response(prompt, tokens, temp)
setwd("~/RPROJECTS/seminarioHD/openAI/data")
generate_response <- function(prompt, tokens, temp) {
# Import the Python module containing the generate_response function
openai_module <- import("elogiosAI.py")  # Replace with the actual module name
# Call the Python function
response <- openai_module$generate_response(prompt, tokens, temp)
return(response)
}
result <- generate_response(prompt, tokens, temp)
generate_response <- function(prompt, tokens, temp) {
# Import the Python module containing the generate_response function
py_run_file ("elogiosAI.py")  # Replace with the actual module name
# Call the Python function
response <- py$generate_response(prompt, tokens, temp)
return(response)
}
result <- generate_response(prompt, tokens, temp)
source_python("seminarioHD/openAI/data/elogiosAI.py")
setwd("~/RPROJECTS")
source_python("seminarioHD/openAI/data/elogiosAI.py")
py$response("Generate a literary praise for Jorge Luis Borges", maxTokens, 0.6)
source_python("seminarioHD/openAI/data/elogiosAI.py")
respuesta <- py$response("Generate a literary praise for Jorge Luis Borges", maxTokens, 0.6)
respuesta
py$generate_response(prompt, tokens, temp)
result <- py$generate_response(prompt, tokens, temp)
py$mytext
# Example usage:
prompt <- "Generate a literary praise for Jorge Luis Borges"
py$generate_response(prompt, tokens, temp)
py$mytext
generate_response <- function(prompt, tokens, temp) {
# Import the Python module containing the generate_response function
py_run_file ("elogiosAI.py")  # Replace with the actual module name
# Call the Python function
response <- py$generate_response(prompt, tokens, temp)
return(response)
}
py$mytext
source_python("seminarioHD/openAI/data/elogiosAI.py")
py$mytext
py$generate_response(prompt, tokens, temp)
source_python("seminarioHD/openAI/data/elogiosAI.py")
py$generate_response(prompt, tokens, temp)
result <- py$generate$response(prompt, tokens, temp)
py$response(prompt, tokens, temp)
py$mytext
result <- py$response(prompt, tokens, temp)
?import
generate_response <- function(prompt, tokens, temp) {
# Import the Python module containing the generate_response function
openai_module <- import("openai")  # Replace with the actual module name
# Call the Python function
response <- openai_module$generate_response(prompt, tokens, temp)
# Extract and return the text from the response
text <- response$choices[[1]]$text
return(text)
}
# Example usage:
prompt <- "Generate a literary praise for Jorge Luis Borges"
tokens <- 60
temp <- 0.7
result <- generate_response(prompt, tokens, temp)
source_python("seminarioHD/openAI/data/elogiosAI.py")
# Example usage:
prompt <- "Generate a literary praise for Jorge Luis Borges"
tokens <- 60
temp <- 0.7
result <- generate_response(prompt, tokens, temp)
py$generate_response(prompt, tokens, temp)
result <- py$generate_response(prompt, tokens, temp)
result <- py$response(prompt, tokens, temp)
result <- py$response(myPrompt, tokens, temp)
tokens <- as.integer(60)
result <- py$response(myPrompt, tokens, temp)
result
cat("Generated response:", result, "\n")
View(result)
source_python("seminarioHD/openAI/data/elogiosAI.py")
result <- py$response(myPrompt, tokens, temp)
source_python("seminarioHD/openAI/data/elogiosAI.py")
result <- py$response(myPrompt, tokens, temp)
source_python("seminarioHD/openAI/data/elogiosAI.py")
result <- py$get_response(myPrompt, tokens, temp)
result
# Example usage:
myPrompt <- "Generate a literary praise for Jorge Luis Borges"
result <- py$get_response(myPrompt, tokens, temp)
result
runApp('seminarioHD/openAI/elogiosApp')
runApp('seminarioHD/openAI/elogiosApp')
runApp('seminarioHD/openAI/elogiosApp')
runApp('seminarioHD/openAI/elogiosApp')
runApp('seminarioHD/openAI/elogiosApp')
runApp('seminarioHD/openAI/elogiosApp')
runApp('seminarioHD/openAI/elogiosApp')
runApp('seminarioHD/openAI/elogiosApp')
runApp('seminarioHD/openAI/elogiosApp')
install.packages("reticulate")
shiny::runApp('seminarioHD/openAI/elogiosApp')
py_install("openai")
runApp('seminarioHD/openAI/elogiosApp')
detach("package:reticulate", unload = TRUE)
pak::pak("rstudio/reticulate")
runApp('seminarioHD/openAI/elogiosApp')
runApp('seminarioHD/openAI/elogiosApp')
shiny::runApp('seminarioHD/openAI/elogiosApp')
runApp('seminarioHD/openAI/elogiosApp')
runApp('seminarioHD/openAI/elogiosApp')
runApp('seminarioHD/openAI/elogiosApp')
library(reticulate)
source_python("seminarioHD/openAI/data/elogiosAI.py")
py_run_string("import os")
runApp('seminarioHD/openAI/elogiosApp')
runApp('seminarioHD/openAI/elogiosApp')
virtualenv_create("elogios")
py_install("openai", envname = "elogios")
py_install("gtts", envname = "elogios")
runApp('seminarioHD/openAI/elogiosApp')
shiny::runApp('seminarioHD/openAI/elogiosApp')
?virtualenv_create
runApp('seminarioHD/openAI/elogiosApp')
runApp('seminarioHD/openAI/elogiosApp')
setwd("~/RPROJECTS/seminarioHD/openAI/elogiosApp")
runApp()
runApp()
